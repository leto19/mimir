{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, string, sys\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow as tf\n",
    "from models import InferSent\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = []\n",
    "\n",
    "# Train\n",
    "with open(\"../../data/question_classification/trec_train.txt\", 'rb') as f:\n",
    "    questions = [x.decode('utf8').strip() for x in f.readlines()]\n",
    "    for q in questions:\n",
    "        splt = q.replace(\"\\n\", \"\").split(\":\")\n",
    "        xtrain.append(\" \".join(splt[1].split(\" \")[1:]))\n",
    "        \n",
    "def preprocess_text(data):\n",
    "    # Remove punctuation\n",
    "    exclude = set(string.punctuation)\n",
    "    data = [''.join(ch for ch in x if ch not in exclude).strip() for x in data]\n",
    "    \n",
    "    # Remove multi-spaces\n",
    "    data = [re.sub(' +', ' ', x) for x in data]\n",
    "    return data\n",
    "\n",
    "xtrain = preprocess_text(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_id</th>\n",
       "      <th>set</th>\n",
       "      <th>question</th>\n",
       "      <th>answer1</th>\n",
       "      <th>answer2</th>\n",
       "      <th>question_tokenized</th>\n",
       "      <th>answer1_tokenized</th>\n",
       "      <th>answer2_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>46765</td>\n",
       "      <td>46765</td>\n",
       "      <td>46765</td>\n",
       "      <td>46765</td>\n",
       "      <td>46765</td>\n",
       "      <td>46765</td>\n",
       "      <td>46765</td>\n",
       "      <td>46765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1572</td>\n",
       "      <td>3</td>\n",
       "      <td>46134</td>\n",
       "      <td>41246</td>\n",
       "      <td>40456</td>\n",
       "      <td>46072</td>\n",
       "      <td>40928</td>\n",
       "      <td>39974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>e0c74cdf270ebe29a2139e7319fc7314738c88ee</td>\n",
       "      <td>train</td>\n",
       "      <td>Where does the story take place?</td>\n",
       "      <td>London</td>\n",
       "      <td>London</td>\n",
       "      <td>Where does the story take place ?</td>\n",
       "      <td>London</td>\n",
       "      <td>London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>50</td>\n",
       "      <td>32747</td>\n",
       "      <td>46</td>\n",
       "      <td>64</td>\n",
       "      <td>60</td>\n",
       "      <td>47</td>\n",
       "      <td>64</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     document_id    set  \\\n",
       "count                                      46765  46765   \n",
       "unique                                      1572      3   \n",
       "top     e0c74cdf270ebe29a2139e7319fc7314738c88ee  train   \n",
       "freq                                          50  32747   \n",
       "\n",
       "                                question answer1 answer2  \\\n",
       "count                              46765   46765   46765   \n",
       "unique                             46134   41246   40456   \n",
       "top     Where does the story take place?  London  London   \n",
       "freq                                  46      64      60   \n",
       "\n",
       "                       question_tokenized answer1_tokenized answer2_tokenized  \n",
       "count                               46765             46765             46765  \n",
       "unique                              46072             40928             39974  \n",
       "top     Where does the story take place ?            London            London  \n",
       "freq                                   47                64                62  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nqa = pd.read_csv(\"../../data/narrativeqa_qas.csv\")\n",
    "nqa.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22192(/24222) words with w2v vectors\n",
      "Vocab size : 22192\n"
     ]
    }
   ],
   "source": [
    "voc = list(nqa['question'])\n",
    "#voc = xtrain\n",
    "\n",
    "\n",
    "V = 2\n",
    "MODEL_PATH = 'encoder/infersent%s.pkl' % V\n",
    "params_model = {'bsize': 64, 'word_emb_dim': 300, 'enc_lstm_dim': 2048,\n",
    "                'pool_type': 'max', 'dpout_model': 0.0, 'version': V}\n",
    "\n",
    "infersent = InferSent(params_model)\n",
    "infersent.load_state_dict(torch.load(MODEL_PATH))\n",
    "\n",
    "W2V_PATH = 'fastText/crawl-300d-2M.vec'\n",
    "infersent.set_w2v_path(W2V_PATH)\n",
    "\n",
    "infersent.build_vocab(voc, tokenize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.saved_model.load('../../dialogue/models/qc_rnn_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_labels = []\n",
    "for x in list(nqa['question']):\n",
    "    enc_q = infersent.encode(np.array([x]), tokenize=True)\n",
    "    reshaped = np.array([x.reshape(1, 4096) for x in enc_q])\n",
    "    tf_test = tf.convert_to_tensor(reshaped)\n",
    "    question_labels.append(model(tf_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Who is Mark Hunter?', 'Where does this radio station take place?', \"Why do more students tune into Mark's show?\", 'Who commits suicide?', 'What does Paige jam into her microwave?', 'What does Mark do with his radio station?', 'What does Mark tell the protesting students?', 'Who gets arrested?', 'What does the radio show cause?', 'Where does Mark Broadcast his station from?']\n",
      "[<tf.Tensor: shape=(1, 6), dtype=float32, numpy=\n",
      "array([[ 3.1534648, -1.1778678,  8.37542  , -1.0564224, -0.2581335,\n",
      "        -3.3743525]], dtype=float32)>, <tf.Tensor: shape=(1, 6), dtype=float32, numpy=\n",
      "array([[ 1.4706217 ,  6.412529  , -0.28377095, -1.6566306 ,  0.666564  ,\n",
      "        -0.19584668]], dtype=float32)>, <tf.Tensor: shape=(1, 6), dtype=float32, numpy=\n",
      "array([[ 8.053342  , -3.3266823 ,  0.57010335,  1.3968505 , -3.3724198 ,\n",
      "        -1.5120921 ]], dtype=float32)>, <tf.Tensor: shape=(1, 6), dtype=float32, numpy=\n",
      "array([[ 2.0118954, -6.0298796, 10.868199 ,  1.9843329, -0.6029846,\n",
      "        -4.4573765]], dtype=float32)>, <tf.Tensor: shape=(1, 6), dtype=float32, numpy=\n",
      "array([[ 3.7270374 , -2.0356464 , -0.06421432,  3.770083  , -1.8134052 ,\n",
      "        -0.9748839 ]], dtype=float32)>, <tf.Tensor: shape=(1, 6), dtype=float32, numpy=\n",
      "array([[ 3.0346503 , -0.5299624 ,  2.4604719 ,  0.09604074,  0.53353494,\n",
      "        -1.5121553 ]], dtype=float32)>, <tf.Tensor: shape=(1, 6), dtype=float32, numpy=\n",
      "array([[ 5.549519  , -2.7816105 ,  0.63424927,  1.5071204 , -0.03989859,\n",
      "        -1.8938818 ]], dtype=float32)>, <tf.Tensor: shape=(1, 6), dtype=float32, numpy=\n",
      "array([[ 2.0673475 , -2.8706033 ,  9.572342  , -0.9719341 , -0.45353755,\n",
      "        -3.3048637 ]], dtype=float32)>, <tf.Tensor: shape=(1, 6), dtype=float32, numpy=\n",
      "array([[ 5.0456905, -3.370035 , -0.7117816,  2.3905544,  1.8434671,\n",
      "        -2.4163585]], dtype=float32)>, <tf.Tensor: shape=(1, 6), dtype=float32, numpy=\n",
      "array([[ 2.655863  ,  5.3540635 ,  0.46014002, -1.2527957 ,  0.65671223,\n",
      "        -1.538985  ]], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "print(list(nqa['question'])[:10])\n",
    "print(question_labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nqa['predicted_answer_class'] = [np.argmax(x) for x in question_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    46765.000000\n",
       "mean         1.588218\n",
       "std          1.403264\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          2.000000\n",
       "75%          2.000000\n",
       "max          5.000000\n",
       "Name: predicted_answer_class, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nqa['predicted_answer_class'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_opts = dict(method='zip',\n",
    "                        archive_name='pred_nqa.csv')\n",
    "\n",
    "nqa.to_csv('pred_nqa.zip', index=False,\n",
    "          compression=compression_opts)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = nqa.sample(n = 100)\n",
    "\n",
    "cls_dict = {\n",
    "  'DESC': 0,\n",
    "  'LOC': 1,\n",
    "  'HUM': 2,\n",
    "  'ENTY': 3,\n",
    "  'ABBR': 4,\n",
    "  'NUM': 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for row in sample:\n",
    "    print(row['question'])\n",
    "    print(row['answer'])\n",
    "    print(row['predicted_answer_class'])\n",
    "    corr = input()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
