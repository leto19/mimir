{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence_transformers\n",
      "  Downloading sentence-transformers-0.3.8.tar.gz (66 kB)\n",
      "\u001b[K     |████████████████████████████████| 66 kB 623 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting transformers<3.4.0,>=3.1.0\n",
      "  Downloading transformers-3.3.1-py3-none-any.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 747 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /home/tomasgoldsack/anaconda3/lib/python3.8/site-packages (from sentence_transformers) (4.47.0)\n",
      "Collecting torch>=1.2.0\n",
      "  Downloading torch-1.6.0-cp38-cp38-manylinux1_x86_64.whl (748.8 MB)\n",
      "\u001b[K     |██▍                             | 55.2 MB 1.7 MB/s eta 0:06:51     |█▏                              | 27.5 MB 783 kB/s eta 0:15:21"
     ]
    }
   ],
   "source": [
    "!pip install sentence_transformers\n",
    "!pip install gensim\n",
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from collections import Counter\n",
    "\n",
    "import gensim.downloader as api\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "stoplist = set(stopwords.words('english'))\n",
    "\n",
    "# vec_model = api.load(\"glove-wiki-gigaword-50\")\n",
    "# api.load(\"glove-twitter-50\")\n",
    "# vec_model['word']\n",
    "\n",
    "sbert_model = SentenceTransformer('bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                            Who is Mark Hunter?\n",
       "1      Where does this radio station take place?\n",
       "2    Why do more students tune into Mark's show?\n",
       "3                           Who commits suicide?\n",
       "4        What does Paige jam into her microwave?\n",
       "Name: question, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../data/narrativeqa_qas.csv\")\n",
    "\n",
    "questions = df.question\n",
    "answers = df.answers\n",
    "\n",
    "questions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_words = set(['who','what','how','where','when','why','which','whom','whose', \"who's\"])\n",
    "other_useful_terms = set([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whitelist = q_words.union(stoplist).union(other_useful_terms)\n",
    "\n",
    "q_contents = []\n",
    "for row in questions:\n",
    "    q_contents.append(\" \".join([word for word in row.lower().split(\" \") if word in whitelist]))\n",
    "    #contents.append(\" \".join([word for word in row.lower().split(\" \")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Counter(contents).most_common(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to sentence embeddings (maybe keep the indexes the same for future reference)\n",
    "sentence_embeddings = []\n",
    "\n",
    "#sentence_data = questions\n",
    "sentence_data = q_contents\n",
    "n_samples = 2000 \n",
    "\n",
    "for row in sentence_data[:n_samples]:\n",
    "    se = sbert_model.encode(row)\n",
    "    sentence_embeddings.append(se)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster sentence embeddings\n",
    "# The silhouette coefficients for each k\n",
    "silhouette_coefficients = []\n",
    "\n",
    "# The Within-Cluster-Sum-of-Squares for each k\n",
    "wcss = []\n",
    "\n",
    "kmeans_kwargs = {\n",
    "    \"init\": \"random\",\n",
    "    \"n_init\": 10,\n",
    "    \"max_iter\": 300,\n",
    "    \"random_state\": 42,\n",
    "}\n",
    "\n",
    "ceil = 15\n",
    "\n",
    "# Silhouette coefficient cannot work with less than 2 clusters\n",
    "for k in range(2, ceil):\n",
    "    kmeans = KMeans(n_clusters=k, **kmeans_kwargs)\n",
    "    kmeans.fit(sentence_embeddings)\n",
    "    score = silhouette_score(sentence_embeddings, kmeans.labels_)\n",
    "    silhouette_coefficients.append(score)\n",
    "    wcss.append(kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"fivethirtyeight\")\n",
    "plt.plot(range(2, ceil), silhouette_coefficients)\n",
    "plt.xticks(range(2, ceil))\n",
    "plt.xlabel(\"Number of Clusters\")\n",
    "plt.ylabel(\"Silhouette Coefficient\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(2, ceil), wcss)\n",
    "plt.xticks(range(2, ceil))\n",
    "plt.xlabel(\"Number of Clusters\")\n",
    "plt.ylabel(\"WCSS\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Off the basis of this second graph, 8 clusters should be used. \n",
    "n_clusters = 5 \n",
    "final_model = KMeans(n_clusters, **kmeans_kwargs)\n",
    "final_model.fit(sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labelled_contents = zip(contents[:500], final_model.labels_)\n",
    "rdf = pd.DataFrame()\n",
    "rdf['sentence'] = sentence_data[:n_samples]\n",
    "rdf['label'] = final_model.labels_\n",
    "rdf['answer1'] = df.answer1[:n_samples]\n",
    "rdf['answer2'] = df.answer2[:n_samples]\n",
    "rdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf.loc[rdf['label'] == 0]\n",
    "\n",
    "#print(contents[1000])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
