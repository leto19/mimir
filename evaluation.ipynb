{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using CPU instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import os.path as op\n",
    "from qa.question_answering.models.model import active_models\n",
    "from qa.question_answering.utils import mimir_dir, data_dir, csv_to_list, tokenize, make_id_name_dict, make_qa_dict_valid\n",
    "from qa.evaluate import Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_name_dict = make_id_name_dict()  # Dictionary of book IDs by name\n",
    "qaps_line_list = csv_to_list(op.join(data_dir, \"narrativeqa_qas.csv\"))\n",
    "qa_dict_valid = make_qa_dict_valid(qaps_line_list, id_name_dict)  # Questions and answers from validation set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_baseline\n"
     ]
    }
   ],
   "source": [
    "models_list = list(active_models.keys())\n",
    "print(models_list[1])\n",
    "qa_dict_debug = {k: v for k, v in list(qa_dict_valid.items())[:10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we are initializing bert baseline\n",
      "bert model\n",
      "bert model to device\n",
      "self.tokenizer\n",
      "initialized\n",
      "we are initializing bert baseline\n",
      "we are initializing bert baseline\n",
      "evaluating q 1 of 10\n",
      "evaluating q 2 of 10\n",
      "evaluating q 3 of 10\n",
      "evaluating q 4 of 10\n",
      "evaluating q 5 of 10\n",
      "evaluating q 6 of 10\n",
      "evaluating q 7 of 10\n",
      "evaluating q 8 of 10\n",
      "evaluating q 9 of 10\n",
      "evaluating q 10 of 10\n",
      "{'testlen': 18, 'reflen': 34, 'guess': [18, 9, 5, 3], 'correct': [8, 3, 1, 0]}\n",
      "ratio: 0.5294117646903115\n",
      "['four phases', 'gargaphie', 'virtues', 'grow dotingly enamored of themselves', 'diana', '', 'asotus', 'narcissus', 'the courtiers and ladies', 'the actor']\n",
      "bleu4_score, bleu1_score, rouge_score, cider_score, accuracy_score\n",
      "(2.304685675163561e-05, 0.18271657353844822, 0.11364697334190103, 0.2782450663981372, 40.0)\n"
     ]
    }
   ],
   "source": [
    "valid_eval = Evaluator(qa_dict_debug, models_list) # for debugging\n",
    "#valid_eval = Evaluator(qa_dict_valid, models_list)\n",
    "extracted_answers = valid_eval.answer_all_questions(models_list[1])\n",
    "scores = valid_eval.score(extracted_answers)\n",
    "print(extracted_answers[:10])\n",
    "print(\"bleu4_score, bleu1_score, rouge_score, cider_score, accuracy_score\")\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
