{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"evaluate_extractive.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyNLru4YxDce5TqFFrxGYl0k"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"sSC0wVWbde8R"},"source":["# Dependencies and helper functions"]},{"cell_type":"code","metadata":{"id":"oXFLDOtmbaG0"},"source":["%%capture\n","!pip install transformers\n","!pip install git+https://github.com/salaniz/pycocoevalcap"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z9SWHsZFb6mP"},"source":["import pandas as pd\n","\n","import time\n","import datetime\n","from string import punctuation\n","\n","def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","    \n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))\n","\n","def clean(text):\n","  '''\n","  Takes a string, removes leading and trailing whitespace,\n","  makes it lower case, and removes leading and trailing punctuation.\n","  '''\n","  text = text.strip() # remove leading and trailing whitespace\n","  text = text.lower() # lower case\n","  text = text.strip(punctuation)\n","\n","  return text"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RF3o2uw1dpwt"},"source":["# Data Pre-processing\n","In this section, we load the data required for training the model and perform any appropriate filtering/pre-processing"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dJBqfwr4bAHZ","executionInfo":{"elapsed":82838,"status":"ok","timestamp":1615995954112,"user":{"displayName":"Kyle G Reed","photoUrl":"","userId":"01028854829176702804"},"user_tz":0},"outputId":"07f695e6-dfb4-4a35-ba4b-3a4248b4bef0"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","ROOT        = 'gdrive/Shared drives/CDT Mini-Project Team 1/Colab Notebooks/'\n","DATA_DIR    = ROOT + 'data/' \n","MODELS_DIR  = ROOT + 'models/'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MF2jgHfAbO21"},"source":["#Load all data\n","qaps = pd.read_csv(DATA_DIR + 'narrativeqa_qas.csv')\n","summaries = pd.read_csv(DATA_DIR + 'summaries.csv')\n","qaps = qaps[qaps['set']=='valid']\n","summaries = summaries[summaries['set']=='valid']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I5sp8-EAErHR"},"source":["summaries = summaries.set_index('document_id')\n","summaries = summaries.drop(labels=['set','summary'],axis='columns')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FLu_De1S0y4q"},"source":["qaps = qaps.set_index('document_id')\n","qaps = qaps.drop(labels=['set','question','answer1','answer2'], axis='columns')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8DemWvy7GKi3"},"source":["# pair qaps with their relevant summaries and drop non-tokenized fields\n","qaps = qaps.join(summaries)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fKc2Rc8Vg7Uf"},"source":["Acquire data in lists of: contexts (summaries), questions, answers"]},{"cell_type":"code","metadata":{"id":"bTHQ7ufUbYlB"},"source":["def format_data(data):\n","  contexts = []\n","  questions = []\n","  answers = []\n","  for index, row in data.iterrows():\n","    context   = row['summary_tokenized']\n","    question  = row['question_tokenized']\n","    answer    = {}\n","    answer['answer1'] = clean(row['answer1_tokenized'])\n","    answer['answer2'] = clean(row['answer2_tokenized'])\n","\n","    contexts.append(context)\n","    questions.append(question)\n","    answers.append(answer)\n","  \n","  return contexts, questions, answers\n","\n","contexts, questions, answers = format_data(qaps)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Eq90La2z9ktM"},"source":["# IF YOU WANT TO RUN TESTS WITH A SMALLER DATASET, UNCOMMENT THE CODE BELOW (ctrl + /)\n","\n","# questions = ['How big is the Empire State Building?', \n","#                    'Who is Shrek married to?',\n","#                    'How old is Gandalf?',\n","#                    'Where does Winnie the Pooh live?']\n","\n","# contexts = ['The Empire State building is a very big building. It is one of the biggest buildings in the world. It is large.', \n","#                   'Shrek is an ogre. There is a common misconception that Shrek is married to Donkey, but he is actually married to Fiona.',\n","#                   'Gandalf is a 900 year old wizard.',\n","#                   'Winnie the Pooh lives in Dalston with some of his uni housemates']\n","\n","# answers = [{'answer1': 'really big', 'answer2': 'very big'},\n","#                  {'answer1': 'Shrek is married to Fiona', 'answer2': 'Fiona'},\n","#                  {'answer1': 'very old', 'answer2': '900 years old'},\n","#                  {'answer1': 'in London', 'answer2': 'near Dalston'}]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d7fOz4-9dyoH"},"source":["# Model information / hyperparameter selection\n","In this section we have details on our model type, and the start-points for training (either a pre-trained model or a partially trained model we wish to resume training)\n","\n","To keep our experiments valid - ensure that the model id is of the form \"modelname-learning-rate\". \n","\n","If you resume training for a model, ensure the learning rates are consistent"]},{"cell_type":"code","metadata":{"id":"AS1qyUVLd5IA","executionInfo":{"status":"ok","timestamp":1615997343935,"user_tz":0,"elapsed":573,"user":{"displayName":"Kyle G Reed","photoUrl":"","userId":"01028854829176702804"}}},"source":["from transformers import BertForQuestionAnswering, BertTokenizerFast, DistilBertTokenizerFast, DistilBertForQuestionAnswering, AutoModelForQuestionAnswering, AutoTokenizer\n","import pickle\n","import os\n","\n","MODEL_IDS = ['distilbert-base-uncased-distilled-squad',\n","             'distilbert-base-cased-distilled-squad',\n","             'bert-large-uncased-whole-word-masking-finetuned-squad',\n","             'mrm8488/longformer-base-4096-finetuned-squadv2',\n","             'distilbert_finetuned',\n","             'bert-large-squad-nqa-3e-5'\n","             'bert-large-squad-nqa-5e-5',\n","             'bert-large-squad-nqa-5e-6',\n","             'Primer/bart-squad2']\n","\n","model_types = ['distilbert', 'bert-base', 'bert-large', 'longformer']\n","\n","# select model id\n","MODEL_ID      = MODEL_IDS[3]\n","model_type    = model_types[3]\n","finetuned     = True            # is the model saved on Drive\n","epoch_to_load = 3               # if a model uploaded to Drive, which epoch to load\n","\n","batch_sizes = {'distilbert': 32, 'bert-base': 32, 'bert-large': 4, 'longformer': 4}"],"execution_count":39,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g-Zm8zlioWLv","executionInfo":{"status":"ok","timestamp":1615997414413,"user_tz":0,"elapsed":69817,"user":{"displayName":"Kyle G Reed","photoUrl":"","userId":"01028854829176702804"}},"outputId":"69fafa2b-e559-4906-9653-7cef55680c38"},"source":["#If we are training from scratch then load up the appropriate model, else load the partially trained model\n","if finetuned:\n","  MODEL_PATH = MODELS_DIR + MODEL_ID\n","  MODEL_PATH = MODEL_PATH + '/epoch' + str(epoch_to_load)\n","  tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n","  model     = AutoModelForQuestionAnswering.from_pretrained(MODEL_PATH,\n","                                                          output_attentions = False,\n","                                                          output_hidden_states=False)\n","  with open(MODEL_PATH + '/stats', \"rb\") as stats:\n","    training_stats = pickle.load(stats)\n","  print('Evaluating {} (finetuned for {} epochs)'.format(MODEL_ID, str(epoch_to_load)))\n","\n","else:\n","  MODEL_PATH = MODEL_ID\n","  tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n","  model     = AutoModelForQuestionAnswering.from_pretrained(MODEL_PATH,\n","                                                          output_attentions = False,\n","                                                          output_hidden_states=False)\n","  print('Evaluating {}'.format(MODEL_ID))\n","\n","\n","batch_size = batch_sizes[model_type]"],"execution_count":40,"outputs":[{"output_type":"stream","text":["Evaluating mrm8488/longformer-base-4096-finetuned-squadv2 (finetuned for 3 epochs)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6lnnoUFndukz"},"source":["# Data tokenization\n","In this section we format our data so it is of the form required for GPU training.\n","\n","Additional features are (likely to be) added here."]},{"cell_type":"code","metadata":{"id":"bZMNbB2JjuUs","executionInfo":{"status":"ok","timestamp":1615997459265,"user_tz":0,"elapsed":4840,"user":{"displayName":"Kyle G Reed","photoUrl":"","userId":"01028854829176702804"}}},"source":["encodings = tokenizer(questions, contexts, truncation='only_second', padding='longest')"],"execution_count":41,"outputs":[]},{"cell_type":"code","metadata":{"id":"kUxfbrGKmHE1","executionInfo":{"status":"ok","timestamp":1615997459272,"user_tz":0,"elapsed":1774,"user":{"displayName":"Kyle G Reed","photoUrl":"","userId":"01028854829176702804"}}},"source":["import torch\n","\n","class NQADataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings):\n","        self.encodings = encodings\n","\n","    def __getitem__(self, idx):\n","        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","\n","    def __len__(self):\n","        return len(self.encodings.input_ids)\n","\n","dataset = NQADataset(encodings)"],"execution_count":42,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2X75_PxgNfu1"},"source":["# Get Answers"]},{"cell_type":"code","metadata":{"id":"lWcZoUuZM7nH","executionInfo":{"status":"ok","timestamp":1615997462340,"user_tz":0,"elapsed":1197,"user":{"displayName":"Kyle G Reed","photoUrl":"","userId":"01028854829176702804"}}},"source":["from torch.utils.data import DataLoader, SequentialSampler\n","\n","loader = DataLoader(\n","            dataset, # The dev samples.\n","            sampler = SequentialSampler(dataset), # Pull out batches sequentially.\n","            batch_size = batch_size) # Evaluate with this batch size."],"execution_count":43,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"24NXcRg8NtBv","executionInfo":{"status":"ok","timestamp":1615998066799,"user_tz":0,"elapsed":604938,"user":{"displayName":"Kyle G Reed","photoUrl":"","userId":"01028854829176702804"}},"outputId":"6dee9a81-409e-4967-edbb-ffd57d130e08"},"source":["device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","\n","if torch.cuda.is_available() : model.cuda()\n","model.to(device)\n","\n","print(\"\")\n","print(\"Getting answers positions...\")\n","\n","total_val_loss = 0\n","t0 = time.time()\n","\n","answer_starts = []\n","answer_ends   = []\n","answer_tokens = []\n","\n","# Put the model in evaluation mode--the dropout layers behave differently\n","# during evaluation.\n","model.eval()\n","\n","# Evaluate data for one epoch\n","for step, batch in enumerate(loader):\n","\n","    # Progress update every 40 batches.\n","    if (step <= 5 or step % 40 == 0) and not step == 0:\n","        # Calculate elapsed time in minutes.\n","        elapsed = format_time(time.time() - t0)\n","            \n","        # Report progress.\n","        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(loader), elapsed))\n","\n","    input_ids = batch['input_ids'].to(device)\n","    attention_mask = batch['attention_mask'].to(device)\n","\n","    # Don't construct a compute graph (only required for backprop during training)\n","    with torch.no_grad():\n","      outputs = model(input_ids, attention_mask=attention_mask)\n","\n","    start_scores = outputs.start_logits\n","    end_scores = outputs.end_logits\n","\n","    for i,score in enumerate(start_scores):\n","      answer_start = torch.argmax(score)\n","      answer_end = answer_start + torch.argmax(end_scores[i][answer_start:])\n","      answer_starts.append(int(answer_start))\n","      answer_ends.append(int(answer_end))\n","      answer_tokens.append(input_ids[i].tolist())\n","\n","# Measure how long the dev run took.\n","dev_time = format_time(time.time() - t0)    \n","print(\"Answering took: {:}\".format(dev_time))"],"execution_count":44,"outputs":[{"output_type":"stream","text":["\n","Getting answers positions...\n","  Batch     1  of    866.    Elapsed: 0:00:01.\n","  Batch     2  of    866.    Elapsed: 0:00:01.\n","  Batch     3  of    866.    Elapsed: 0:00:02.\n","  Batch     4  of    866.    Elapsed: 0:00:03.\n","  Batch     5  of    866.    Elapsed: 0:00:03.\n","  Batch    40  of    866.    Elapsed: 0:00:28.\n","  Batch    80  of    866.    Elapsed: 0:00:56.\n","  Batch   120  of    866.    Elapsed: 0:01:24.\n","  Batch   160  of    866.    Elapsed: 0:01:51.\n","  Batch   200  of    866.    Elapsed: 0:02:20.\n","  Batch   240  of    866.    Elapsed: 0:02:48.\n","  Batch   280  of    866.    Elapsed: 0:03:16.\n","  Batch   320  of    866.    Elapsed: 0:03:44.\n","  Batch   360  of    866.    Elapsed: 0:04:12.\n","  Batch   400  of    866.    Elapsed: 0:04:40.\n","  Batch   440  of    866.    Elapsed: 0:05:08.\n","  Batch   480  of    866.    Elapsed: 0:05:36.\n","  Batch   520  of    866.    Elapsed: 0:06:04.\n","  Batch   560  of    866.    Elapsed: 0:06:32.\n","  Batch   600  of    866.    Elapsed: 0:07:00.\n","  Batch   640  of    866.    Elapsed: 0:07:28.\n","  Batch   680  of    866.    Elapsed: 0:07:55.\n","  Batch   720  of    866.    Elapsed: 0:08:23.\n","  Batch   760  of    866.    Elapsed: 0:08:51.\n","  Batch   800  of    866.    Elapsed: 0:09:19.\n","  Batch   840  of    866.    Elapsed: 0:09:47.\n","Answering took: 0:10:04\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZULkkAGcR97v","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615998066801,"user_tz":0,"elapsed":602538,"user":{"displayName":"Kyle G Reed","photoUrl":"","userId":"01028854829176702804"}},"outputId":"43d1bd0f-fa97-41b9-95d3-33af7648fdc4"},"source":["# Get answers using positions\n","print(\"Getting answers...\")\n","\n","for i,(source,answer_start,answer_end) in enumerate(zip(answer_tokens, answer_starts,answer_ends)):\n","  answer = tokenizer.decode(source[answer_start:answer_end+1])\n","  answers[i]['extracted_answer'] = clean(answer)\n","\n","print(\"\")\n","print(\"Extracted answers\")"],"execution_count":45,"outputs":[{"output_type":"stream","text":["Getting answers...\n","\n","Extracted answers\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ATrrWACwyy6U","executionInfo":{"status":"ok","timestamp":1615998066802,"user_tz":0,"elapsed":602014,"user":{"displayName":"Kyle G Reed","photoUrl":"","userId":"01028854829176702804"}},"outputId":"ce69c425-c9f6-4ab7-8237-f2a8f634ae84"},"source":["for answer in answers[:5]:\n","  print(answer)"],"execution_count":46,"outputs":[{"output_type":"stream","text":["{'answer1': 'the actor wearing the black cloak', 'answer2': 'the actor in the black cloak', 'extracted_answer': 'diana'}\n","{'answer1': 'the goddess diana', 'answer2': 'the goddess diana', 'extracted_answer': 'queen elizabeth'}\n","{'answer1': 'narcissus', 'answer2': 'narcissus', 'extracted_answer': 'narcissus'}\n","{'answer1': 'fall in love with themselves', 'answer2': 'grow dotingly enamored with themselves', 'extracted_answer': 'grow dotingly enamored of themselves'}\n","{'answer1': 'gargaphie in greece', 'answer2': 'gargaphie', 'extracted_answer': 'gargaphie'}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XuBLd7F5A0mx"},"source":["# Evaluation metrics"]},{"cell_type":"code","metadata":{"id":"1K9Qvxc4BkbA","executionInfo":{"status":"ok","timestamp":1615998067158,"user_tz":0,"elapsed":598591,"user":{"displayName":"Kyle G Reed","photoUrl":"","userId":"01028854829176702804"}}},"source":["from pycocoevalcap.meteor.meteor import Meteor\n","from pycocoevalcap.cider.cider import Cider\n","from pycocoevalcap.rouge.rouge import Rouge\n","from pycocoevalcap.bleu.bleu import Bleu\n","\n","meteor_obj = Meteor()\n","rouge_obj = Rouge()\n","cider_obj = Cider()\n","bleu_obj = Bleu(4)"],"execution_count":47,"outputs":[]},{"cell_type":"code","metadata":{"id":"N59hqiELDdbN","executionInfo":{"status":"ok","timestamp":1615998067161,"user_tz":0,"elapsed":597139,"user":{"displayName":"Kyle G Reed","photoUrl":"","userId":"01028854829176702804"}}},"source":["ref1_strs = [answer['answer1'] for answer in answers]\n","ref2_strs = [answer['answer2'] for answer in answers]\n","sys_strs  = [answer['extracted_answer'] for answer in answers]\n","\n","assert len(ref1_strs) == len(ref2_strs)\n","assert len(ref2_strs) == len(sys_strs)"],"execution_count":48,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dU8A1T3PFFR4","executionInfo":{"status":"ok","timestamp":1615998082625,"user_tz":0,"elapsed":611427,"user":{"displayName":"Kyle G Reed","photoUrl":"","userId":"01028854829176702804"}},"outputId":"40a9fae4-432f-444e-f325-07db0a78f8d4"},"source":["word_target_dict = {}\n","word_response_dict = {}\n","\n","for i in range(len(ref1_strs)):\n","    word_target_dict[i] = [ref1_strs[i], ref2_strs[i]]\n","    word_response_dict[i] = [sys_strs[i]]\n","\n","\n","bleu_score, bleu_scores = bleu_obj.compute_score(\n","        word_target_dict, word_response_dict,\n","        verbose=False)\n","bleu1_score, _, _, bleu4_score = bleu_score\n","bleu1_scores, _, _, bleu4_scores = bleu_scores\n","meteor_score, meteor_scores = meteor_obj.compute_score(\n","        word_target_dict, word_response_dict) \n","rouge_score, rouge_scores = rouge_obj.compute_score(\n","        word_target_dict, word_response_dict) \n","cider_score, cider_scores = cider_obj.compute_score(\n","        word_target_dict, word_response_dict)\n","\n","ref1_comparison = [a == b for a,b in zip(ref1_strs, sys_strs)]                  # For each question, True if extracted answer matches answer1\n","ref2_comparison = [a == b for a,b in zip(ref2_strs, sys_strs)]                  # For each question, True if extracted answer matches answer2\n","ref_comparison = [int(a or b) for a,b in zip(ref1_comparison, ref2_comparison)] # For each question, 1 if extracted answer matches either answer1 or answer2, else 0\n","accuracy = sum(ref_comparison) / len(ref_comparison)\n","\n","print(\"ROUGE-L : \", round(100*rouge_score,2))\n","print(\"BLEU-1  : \", round(100*bleu1_score,2))\n","print(\"BLEU-4  : \", round(100*bleu4_score,2))\n","print(\"METEOR  : \", round(100*meteor_score,2))\n","print(\"CiDER   : \", round(100*cider_score,2))\n","print(\"Accuracy: \", round(100*accuracy, 2))"],"execution_count":49,"outputs":[{"output_type":"stream","text":["ROUGE-L :  55.42\n","BLEU-1  :  22.03\n","BLEU-4  :  7.66\n","METEOR  :  22.05\n","CiDER   :  212.01\n","Accuracy:  30.8\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xgJD65TKHOy4","executionInfo":{"status":"ok","timestamp":1615998155476,"user_tz":0,"elapsed":635,"user":{"displayName":"Kyle G Reed","photoUrl":"","userId":"01028854829176702804"}}},"source":["import pickle\n","\n","with open(DATA_DIR+'longformer_finetuned', 'wb') as f: \n","  pickle.dump(answers, f)"],"execution_count":51,"outputs":[]},{"cell_type":"code","metadata":{"id":"0f4aeBQa62SJ"},"source":[""],"execution_count":null,"outputs":[]}]}